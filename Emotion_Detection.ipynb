{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGMZxCkXXdKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69325bd-2780-40be-d9c1-93a22f398385"
      },
      "source": [
        "!wget https://www.dropbox.com/s/nilt43hyl1dx82k/dataset.zip?dl=0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-30 15:29:09--  https://www.dropbox.com/s/nilt43hyl1dx82k/dataset.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/nilt43hyl1dx82k/dataset.zip [following]\n",
            "--2023-07-30 15:29:09--  https://www.dropbox.com/s/raw/nilt43hyl1dx82k/dataset.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3f8f2ae847a4d8aba1aa287086.dl.dropboxusercontent.com/cd/0/inline/CA2IkOWQSREjRKHtY1b6aqASv1QEj-4eni3ZWX3oYdgLqew8ZGwLdKcLIKI6-qZRsZcAbgJOKBxh2Udck8vBbD82dQXyjA1Wcgjxxi_NIYsEp0s2_YH6LSXi3TW4qY-M5Pk5ggioYM2Yv0t-xM6a1nb3/file# [following]\n",
            "--2023-07-30 15:29:10--  https://uc3f8f2ae847a4d8aba1aa287086.dl.dropboxusercontent.com/cd/0/inline/CA2IkOWQSREjRKHtY1b6aqASv1QEj-4eni3ZWX3oYdgLqew8ZGwLdKcLIKI6-qZRsZcAbgJOKBxh2Udck8vBbD82dQXyjA1Wcgjxxi_NIYsEp0s2_YH6LSXi3TW4qY-M5Pk5ggioYM2Yv0t-xM6a1nb3/file\n",
            "Resolving uc3f8f2ae847a4d8aba1aa287086.dl.dropboxusercontent.com (uc3f8f2ae847a4d8aba1aa287086.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc3f8f2ae847a4d8aba1aa287086.dl.dropboxusercontent.com (uc3f8f2ae847a4d8aba1aa287086.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CA12pRa7Ymj8ty0YLX3FAXBAkcHyAtETLrxdI5ThN8tnqh6_Di2uRHUoLIWh8Y8lGsxEN49tETvY02FIF-CsBUFVqTLIqAqFlkiUsUG8b1hMbmMmRiPBIY1dO_RD0Hc3FBFE1-c4Wpb7EY6VUxj83bk_ACQdeW-m-vr0rkWoaCbul_Bp-RCtL4ojQeRgZV_RaCBtGqN0cTvQ4CYQJ021qKiEou2Yngl5oXilVFJcWqLhllOL0k0HiUGva1_-1l1vhXIljyW77kSibgBVlitIi0doqMYT_Hkfqo9K5AyzH1Zi1Cq7C0SsL22jxJHFb67LAT3MZ_TIZ79wQf1FAsxZi5uWdGxwhOFOxNhC0jJaW7UlCYR9joLS9bhbyO0JgXgGcyA/file [following]\n",
            "--2023-07-30 15:29:10--  https://uc3f8f2ae847a4d8aba1aa287086.dl.dropboxusercontent.com/cd/0/inline2/CA12pRa7Ymj8ty0YLX3FAXBAkcHyAtETLrxdI5ThN8tnqh6_Di2uRHUoLIWh8Y8lGsxEN49tETvY02FIF-CsBUFVqTLIqAqFlkiUsUG8b1hMbmMmRiPBIY1dO_RD0Hc3FBFE1-c4Wpb7EY6VUxj83bk_ACQdeW-m-vr0rkWoaCbul_Bp-RCtL4ojQeRgZV_RaCBtGqN0cTvQ4CYQJ021qKiEou2Yngl5oXilVFJcWqLhllOL0k0HiUGva1_-1l1vhXIljyW77kSibgBVlitIi0doqMYT_Hkfqo9K5AyzH1Zi1Cq7C0SsL22jxJHFb67LAT3MZ_TIZ79wQf1FAsxZi5uWdGxwhOFOxNhC0jJaW7UlCYR9joLS9bhbyO0JgXgGcyA/file\n",
            "Reusing existing connection to uc3f8f2ae847a4d8aba1aa287086.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63252113 (60M) [application/zip]\n",
            "Saving to: ‘dataset.zip?dl=0.1’\n",
            "\n",
            "dataset.zip?dl=0.1  100%[===================>]  60.32M  32.9MB/s    in 1.8s    \n",
            "\n",
            "2023-07-30 15:29:13 (32.9 MB/s) - ‘dataset.zip?dl=0.1’ saved [63252113/63252113]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V-kwycpXtDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68baf2f-44e8-429f-8984-f64a13a2a73b"
      },
      "source": [
        "!unzip dataset.zip?dl=0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.zip?dl=0\n",
            "replace test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dcwbXc8Xzww"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "#from keras.preprocessing.image import ImageDataGenerator , img_to_array, load_img\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.losses import categorical_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQRxQ8qNbvE0"
      },
      "source": [
        "#  Building our Model To train the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HCUQigdYELf"
      },
      "source": [
        "# Working with pre trained model\n",
        "\n",
        "base_model = MobileNet( input_shape=(224,224,3), include_top= False )\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(units=7 , activation='softmax' )(x)\n",
        "\n",
        "# creating our model.\n",
        "model = Model(base_model.input, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN3kEpAeZUGj"
      },
      "source": [
        "model.compile(optimizer='adam', loss= categorical_crossentropy , metrics=['accuracy']  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kh9_hjbs47"
      },
      "source": [
        "# Preparing our data using data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpxBuUAlbmh8"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "     zoom_range = 0.2,\n",
        "     shear_range = 0.2,\n",
        "     horizontal_flip=True,\n",
        "     rescale = 1./255\n",
        ")\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(directory= \"/content/train\",\n",
        "                                               target_size=(224,224),\n",
        "                                               batch_size=32,\n",
        "                                  )\n",
        "\n",
        "\n",
        "train_data.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x-TwUhocaHn"
      },
      "source": [
        "val_datagen = ImageDataGenerator(rescale = 1./255 )\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(directory= \"/content/test\",\n",
        "                                           target_size=(224,224),\n",
        "                                           batch_size=32,\n",
        "                                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNDgYni5c8Qk"
      },
      "source": [
        "# visualizaing the data that is fed to train data gen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tVIpYKDc2a_"
      },
      "source": [
        "# to visualize the images in the traing data denerator\n",
        "\n",
        "t_img , label = train_data.next()\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "# function when called will prot the images\n",
        "def plotImages(img_arr, label):\n",
        "  \"\"\"\n",
        "  input  :- images array\n",
        "  output :- plots the images\n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  for im, l in zip(img_arr,label) :\n",
        "    plt.imshow(im)\n",
        "    plt.title(im.shape)\n",
        "    plt.axis = False\n",
        "    plt.show()\n",
        "\n",
        "    count += 1\n",
        "    if count == 10:\n",
        "      break\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "# function call to plot the images\n",
        "plotImages(t_img, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhuAjX8KfPa-"
      },
      "source": [
        "# having early stopping and model check point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XtYmjt5dZ2c"
      },
      "source": [
        "## having early stopping and model check point\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# early stopping\n",
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n",
        "\n",
        "# model check point\n",
        "mc = ModelCheckpoint(filepath=\"best_model.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
        "\n",
        "# puting call back in a list\n",
        "call_back = [es, mc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GxQ9-qSfT3K"
      },
      "source": [
        "hist = model.fit_generator(train_data,\n",
        "                           steps_per_epoch= 10,\n",
        "                           epochs= 30,\n",
        "                           validation_data= val_data,\n",
        "                           validation_steps= 8,\n",
        "                           callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6YSss56fWrD"
      },
      "source": [
        "\n",
        "# Loading the best fit model\n",
        "from keras.models import load_model\n",
        "model = load_model(\"/content/best_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd0p7xDzfe2V"
      },
      "source": [
        "h =  hist.history\n",
        "h.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qm3Qz11fhMy"
      },
      "source": [
        "plt.plot(h['accuracy'])\n",
        "plt.plot(h['val_accuracy'] , c = \"red\")\n",
        "plt.title(\"acc vs v-acc\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Z9fjdZfjcU"
      },
      "source": [
        "plt.plot(h['loss'])\n",
        "plt.plot(h['val_loss'] , c = \"red\")\n",
        "plt.title(\"loss vs v-loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mj02ddxjTyr"
      },
      "source": [
        "# just to map o/p values\n",
        "op = dict(zip( train_data.class_indices.values(), train_data.class_indices.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xRgvdZZfltN"
      },
      "source": [
        "# path for the image to see if it predics correct class\n",
        "\n",
        "path = \"/content/happy_old_lady.jpg\"\n",
        "img = load_img(path, target_size=(224,224) )\n",
        "\n",
        "i = img_to_array(img)/255\n",
        "input_arr = np.array([i])\n",
        "input_arr.shape\n",
        "\n",
        "pred = np.argmax(model.predict(input_arr))\n",
        "\n",
        "print(f\" the image is of {op[pred]}\")\n",
        "\n",
        "# to display the image\n",
        "plt.imshow(input_arr[0])\n",
        "plt.title(\"input image\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woVkimceN8Jr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}